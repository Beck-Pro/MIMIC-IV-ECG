{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D ECGNET training\n",
    "모델 참고 코드\n",
    "- https://www.kaggle.com/code/nischaydnk/lightning-1d-eegnet-training-pipeline-hbs/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, WeightedRandomSampler\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score, BinaryAUROC\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "import pywt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    fs = 500\n",
    "    csv_path = './train_fib.csv'\n",
    "    wave_dir = './wave'\n",
    "    output_dir = './output'\n",
    "    batch_size = 32\n",
    "    epochs = 30\n",
    "    lr = 1e-3\n",
    "    folds = [0, 1, 2, 3, 4]\n",
    "    seed = 42\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_highpass_filter(data, cutoff=0.5, fs=500, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff=150, fs=500, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def notch_filter(data, freq=60.0, fs=500.0, Q=30.0):\n",
    "    b, a = iirnotch(freq / (0.5 * fs), Q)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, df, ecg_dir, test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.ecg_dir = ecg_dir\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        row = self.df.iloc[index]\n",
    "        path = os.path.join(self.ecg_dir, f\"{row.study_id}.npy\")\n",
    "        signal = np.load(path)\n",
    "        signal = np.nan_to_num(signal)\n",
    "        signal = np.clip(signal, -1024, 1024) / 32.0\n",
    "\n",
    "        signal = butter_highpass_filter(signal, cutoff = 0.5, fs=CFG.fs) \n",
    "        signal = butter_lowpass_filter(signal, cutoff = 150, fs=CFG.fs)\n",
    "        signal = notch_filter(signal, freq =60.0, fs=CFG.fs)\n",
    "        signal = signal.copy()\n",
    "\n",
    "        x = torch.tensor(signal, dtype=torch.float32).permute(1, 0)  # shape: (12, 5000)\n",
    "        if self.test:\n",
    "            return x\n",
    "        y = torch.tensor(row.report_0, dtype=torch.float32)\n",
    "        return x, y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_1D_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, downsampling):\n",
    "        super().__init__()\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.maxpool = nn.MaxPool1d(2)\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.downsampling(x)\n",
    "        out = self.relu(self.bn1(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.relu(self.bn2(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.maxpool(out)\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "class ECGNet(nn.Module):\n",
    "    def __init__(self, kernels, in_channels=12, fixed_kernel_size=17, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels, self.planes, k, 1, 0, bias=False) for k in kernels\n",
    "        ])\n",
    "        self.bn1 = nn.BatchNorm1d(self.planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv1d(self.planes, self.planes, fixed_kernel_size, 2, 2, bias=False)\n",
    "        self.block = self._make_resnet_layer(fixed_kernel_size, 1, 9, fixed_kernel_size // 2)\n",
    "        self.bn2 = nn.BatchNorm1d(self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(6, 6, 2)\n",
    "        self.rnn = nn.GRU(input_size=in_channels, hidden_size=128, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(328, num_classes)\n",
    "\n",
    "    def _make_resnet_layer(self, kernel_size, stride, blocks, padding):\n",
    "        layers = []\n",
    "        for _ in range(blocks):\n",
    "            downsampling = nn.Sequential(nn.MaxPool1d(2))\n",
    "            layers.append(ResNet_1D_Block(self.planes, self.planes, kernel_size, stride, padding, downsampling))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([conv(x) for conv in self.parallel_conv], dim=2)\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = self.conv1(out)\n",
    "        out = self.block(out)\n",
    "        out = self.relu(self.bn2(out))\n",
    "        out = self.avgpool(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "\n",
    "        return self.fc(new_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Validate loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y in tqdm(loader, desc=\"Train\"):\n",
    "        x, y = x.to(CFG.device), y.to(CFG.device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x).squeeze(1)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def valid_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Valid\"):\n",
    "            x, y = x.to(CFG.device), y.to(CFG.device)\n",
    "            out = model(x).squeeze(1)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item()\n",
    "            prob = torch.sigmoid(out).cpu().numpy()\n",
    "            preds.extend(prob)\n",
    "            targets.extend(y.cpu().numpy())\n",
    "    return total_loss / len(loader), preds, targets\n",
    "\n",
    "\n",
    "def train_loop(fold_id, df):\n",
    "    print(f\"===== Fold {fold_id} =====\")\n",
    "    train_df = df[df.fold != fold_id].copy()\n",
    "    val_df = df[df.fold == fold_id].copy()\n",
    "\n",
    "    train_ds = ECGDataset(train_df, CFG.wave_dir)\n",
    "    val_ds = ECGDataset(val_df, CFG.wave_dir)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = ECGNet(kernels=[3, 5, 7, 9]).to(CFG.device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n",
    "\n",
    "    best_auc = 0\n",
    "    for epoch in range(CFG.epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{CFG.epochs}\")\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, preds, targets = valid_epoch(model, val_loader, criterion)\n",
    "\n",
    "        bin_preds = [int(p > 0.5) for p in preds]\n",
    "\n",
    "        # metric\n",
    "        acc = accuracy_score(targets, bin_preds)\n",
    "        f1 = f1_score(targets, bin_preds)\n",
    "        auc = roc_auc_score(targets, preds)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Val Acc: {acc:.4f} | F1: {f1:.4f} | AUROC: {auc:.4f}\")\n",
    "\n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            torch.save(model.state_dict(), os.path.join(CFG.output_dir, f\"ecgnet_fold{fold_id}.pt\"))\n",
    "            print(\"Best model saved.\")\n",
    "\n",
    "    # Save validation predictions\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    val_df['pred'] = preds\n",
    "    val_df.to_csv(os.path.join(CFG.output_dir, f\"pred_df_f{fold_id}.csv\"), index=False)\n",
    "    return val_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(CFG.output_dir, exist_ok=True)\n",
    "\n",
    "# csv 불러오기\n",
    "df = pd.read_csv(CFG.csv_path)\n",
    "df = df.dropna(subset=['report_0', 'study_id'])\n",
    "\n",
    "# stratifiedkfold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
    "df['fold'] = -1\n",
    "for i, (_, val_idx) in enumerate(skf.split(df, df['report_0'])):\n",
    "    df.loc[val_idx, 'fold'] = i\n",
    "\n",
    "all_oof = []\n",
    "for fold in CFG.folds:\n",
    "    val_result = train_loop(fold, df)\n",
    "    all_oof.append(val_result)\n",
    "\n",
    "oof_df = pd.concat(all_oof).reset_index(drop=True)\n",
    "oof_df.to_csv(os.path.join(CFG.output_dir, \"oof_preds.csv\"), index=False)\n",
    "print(\"\\n All folds complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "model = ECGNet(kernels=[3, 5, 7, 9]).to(CFG.device)\n",
    "model_dict = torch.load('./output/ecgnet_fold4.pt')\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, df, wave_dir, threshold=0.5, batch_size=32):\n",
    "    ds = ECGDataset(df, wave_dir, test=True)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x in loader:\n",
    "            x = x.to(CFG.device)\n",
    "            output = model(x).squeeze()\n",
    "            probs = torch.sigmoid(output).cpu().numpy()\n",
    "            probs = np.atleast_1d(probs)\n",
    "            preds.extend(probs)\n",
    "\n",
    "    df = df.copy()\n",
    "    df['pred_proba'] = preds\n",
    "    df['pred_label'] = (df['pred_proba'] >= threshold).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test_fib.csv')  # your test set\n",
    "pred_df = predict(model, test_df, './wave', threshold=0.5)\n",
    "pred_df.to_csv('./output/test_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report_0\n",
       "0    3747\n",
       "1     446\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.report_0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9666110183639399\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도:\", (pred_df['report_0'] == pred_df['pred_label']).mean()) # filtering 한 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.8936322442165514\n"
     ]
    }
   ],
   "source": [
    "p = pd.read_csv('./output/test_preds_wo_pre.csv') # filtering 하기 전\n",
    "print(\"정확도:\", (p['report_0'] == p['pred_label']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
